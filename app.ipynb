{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROHME 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `crohme_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.crohme_dataset  # Register `crohme_dataset`\n",
    "\n",
    "ds = tfds.load(\"crohme_dataset\")  # `crohme_dataset` registered\n",
    "test: tf.data.Dataset = ds[\"test\"]\n",
    "train: tf.data.Dataset = ds[\"train\"]\n",
    "validation: tf.data.Dataset = ds[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Previewing InkML Files\n",
    "\n",
    "I also created a little utility in C++ and GTK to render out an inkml file from the dataset. It reads the InkML file, and renders out the strokes as well as the LaTeX of what it's supposed to be. It was a fun project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeshwinprince/Programming/crohme/datasets/crohme_dataset/data/INKML/val/CROHME2016_test/UN_130_em_1061.inkml\n",
      "Displaying app now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "random_data_point = next(iter(validation.shuffle(200_000).take(1)))\n",
    "filepath = random_data_point[\"filepath\"].numpy().decode(\"ascii\")\n",
    "os.system(f\"inkmlviewer {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Text Vectorization\n",
    "\n",
    "We will use `pylatexenc` to parse the LaTeX into nodes for custom splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.latexwalker import (\n",
    "    LatexWalker,\n",
    "    LatexMacroNode,\n",
    "    LatexEnvironmentNode,\n",
    "    LatexCharsNode,\n",
    "    LatexGroupNode,\n",
    ")\n",
    "\n",
    "START_TOKEN, END_TOKEN = \"<START>\", \"<END>\"\n",
    "\n",
    "\n",
    "# Define the tokenization function using pylatexenc\n",
    "def latex_tokenizer(latex_string):\n",
    "    \"\"\"\n",
    "    Tokenizes a LaTeX string into tokens using pylatexenc.\n",
    "    \"\"\"\n",
    "    if not latex_string:\n",
    "        return []\n",
    "    walker = LatexWalker(latex_string)\n",
    "\n",
    "    def parse_node(nodelist):\n",
    "        if len(nodelist) == 0:\n",
    "            return []\n",
    "        try:\n",
    "            tokens = []\n",
    "            for node in nodelist:\n",
    "                if not node:\n",
    "                    continue\n",
    "                elif node.isNodeType(LatexMacroNode):\n",
    "                    tokens.append(f\"\\\\{node.macroname}\")\n",
    "                    # Parse arguments if they exist\n",
    "                    tokens += parse_node(node.nodeargd.argnlist)\n",
    "                elif node.isNodeType(LatexEnvironmentNode):\n",
    "                    tokens.append(f\"\\\\begin{{{node.environmentname}}}\")\n",
    "                    tokens += parse_node(node.nodeargd.argnlist)\n",
    "                    tokens += parse_node(node.nodelist)\n",
    "                    tokens.append(f\"\\\\end{{{node.environmentname}}}\")\n",
    "                elif node.isNodeType(LatexCharsNode):\n",
    "                    tokens += list(node.chars)\n",
    "                elif node.isNodeType(LatexGroupNode):\n",
    "                    tokens.append(node.delimiters[0])\n",
    "                    tokens += parse_node(node.nodelist)\n",
    "                    tokens.append(node.delimiters[1])\n",
    "            return tokens\n",
    "        except Exception as e:\n",
    "            return []\n",
    "\n",
    "    nodelist, _, _ = walker.get_latex_nodes()\n",
    "    return parse_node(nodelist)\n",
    "\n",
    "\n",
    "# Wrap the tokenizer for use in TextVectorization\n",
    "def tokenize_fn(latex_tensor):\n",
    "    tokens = []\n",
    "    for latex_string in latex_tensor:\n",
    "        tokenized_string = latex_tokenizer(latex_string.numpy().decode(\"utf-8\"))\n",
    "        tokenized_string.insert(0, START_TOKEN)\n",
    "        tokenized_string.append(END_TOKEN)\n",
    "        tokens.append(tokenized_string)\n",
    "    return tf.ragged.constant(tokens, dtype=tf.string)\n",
    "\n",
    "\n",
    "# Create a TensorFlow-compatible wrapper\n",
    "@tf.function\n",
    "def tf_tokenizer(latex_string):\n",
    "    return tf.py_function(\n",
    "        func=tokenize_fn,\n",
    "        inp=[latex_string],\n",
    "        Tout=tf.RaggedTensorSpec([None, None], dtype=tf.string),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the vectorizer and use a vocabulary file to adapt it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 17:48:18.367433: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Create the TextVectorization layer\n",
    "max_tokens = 10000  # Adjust depending on your vocabulary size\n",
    "\n",
    "vectorizer = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    standardize=None,  # Custom tokenizer, so no built-in preprocessing\n",
    "    split=tf_tokenizer,\n",
    "    ragged=True,\n",
    ")\n",
    "dataset = tf.data.TextLineDataset(\"vocabulary.txt\")\n",
    "dataset = dataset.map(lambda line: [line])\n",
    "vectorizer.adapt(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it out to make sure it works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[4, 60, 45, 11, 45, 30, 39, 9, 12, 5],\n",
      " [4, 20, 3, 21, 2, 3, 38, 2, 45, 18, 45, 79, 3, 39, 2, 5],\n",
      " [4, 73, 6, 3, 19, 11, 10, 2, 9, 16, 45, 19, 9, 12, 45, 11, 45, 20, 3, 16,\n",
      "  7, 16, 18, 10, 8, 7, 12, 16, 18, 10, 8, 2, 3, 92, 2, 5]                 ,\n",
      " [4, 34, 45, 11, 45, 78, 27, 9, 12, 5],\n",
      " [4, 76, 11, 165, 10, 154, 10, 17, 154, 17, 75, 45, 245, 245, 245, 76, 9, 3,\n",
      "  69, 2, 75, 45, 164, 5]                                                    ]>\n",
      "<START>E = mc^2<END>\n"
     ]
    }
   ],
   "source": [
    "def latex_to_token(string):\n",
    "    return vectorizer(string)\n",
    "\n",
    "\n",
    "id_to_token = {i: token for i, token in enumerate(vectorizer.get_vocabulary())}\n",
    "\n",
    "\n",
    "def token_to_latex(tokens):\n",
    "    return \"\".join([id_to_token[id] for id in tokens.numpy()])\n",
    "\n",
    "\n",
    "latex_array = [\n",
    "    r\"E = mc^2\",\n",
    "    r\"\\frac{a}{b} + \\sqrt{c}\",\n",
    "    r\"\\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6}\",\n",
    "    r\"A = \\pi r^2\",\n",
    "    r\"G=\\begin{bmatrix}1&\\dots&1&0&\\dots&0\\\\ \\ast&\\ast&\\ast&&G^{\\prime}&\\\\ \\end{bmatrix}\",\n",
    "]\n",
    "latex_data = tf.constant(latex_array)\n",
    "\n",
    "# Tokenize and vectorize\n",
    "tokenized_output = latex_to_token(latex_data)\n",
    "print(tokenized_output)\n",
    "\n",
    "E_mc2 = token_to_latex(tokenized_output[0])\n",
    "print(E_mc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the config as a pickle just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the configuration\n",
    "vectorizer_config = vectorizer.get_config()\n",
    "\n",
    "# Save the vocabulary as a list\n",
    "vectorizer_vocab = vectorizer.get_vocabulary()\n",
    "\n",
    "# Bundle the config and vocab into a dictionary\n",
    "vectorizer_data = {\n",
    "    \"config\": vectorizer_config,\n",
    "    \"vocab\": vectorizer_vocab,\n",
    "}\n",
    "\n",
    "# Write to a pickle file\n",
    "with open(\"notebook_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Strokes\n",
    "\n",
    "Instead of images, this model takes in a stream of strokes, such as writing with a stylus on a tablet. Our dataset gives us a list of strokes, and each stroke is itself a list of coordinates [x, y] of the position of the stylus. Both the number of strokes and the length of each strokes changes for every value in our dataset, so we are going to pre-process the stroke data so it will be normalized (scaled to be between 0 and 1), and always fit in a tensor with shape `(64, 64, 2,)`. FOr this, I am using the [Ramer-Douglas-Peucker Algorithm](https://en.wikipedia.org/wiki/Ramer%E2%80%93Douglas%E2%80%93Peucker_algorithm) for polyline decimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_strokes(strokes: tf.RaggedTensor):\n",
    "    # First, scale values to between 0.0 and 1.0\n",
    "    min_vals = tf.reduce_min(strokes, axis=(0, 1))\n",
    "    max_vals = tf.reduce_max(strokes, axis=(0, 1))\n",
    "    normalized_strokes = tf.map_fn(\n",
    "        elems=strokes,\n",
    "        fn=lambda stroke: (stroke - min_vals) / (max_vals - min_vals + 1e-6),\n",
    "    )\n",
    "\n",
    "    def point_line_distance(point, start, end):\n",
    "        \"\"\"\n",
    "        Calculate the perpendicular distance from `point` to the line segment\n",
    "        defined by `start` and `end`.\n",
    "        \"\"\"\n",
    "         # Convert to 3D by adding a zero z-component\n",
    "        point_3d = tf.concat([point, tf.zeros([1], dtype=tf.float32)], axis=0)\n",
    "        start_3d = tf.concat([start, tf.zeros([1], dtype=tf.float32)], axis=0)\n",
    "        end_3d = tf.concat([end, tf.zeros([1], dtype=tf.float32)], axis=0)\n",
    "        \n",
    "        # Compute the cross product between the vectors\n",
    "        cross_prod = tf.linalg.cross(end_3d - start_3d, point_3d - start_3d)\n",
    "        \n",
    "        # Return the perpendicular distance (norm of the cross product / norm of the line segment)\n",
    "        return tf.norm(cross_prod) / tf.norm(end_3d - start_3d)\n",
    "\n",
    "    def douglas_peucker(stroke, epsilon=0.01):\n",
    "        \"\"\"\n",
    "        Non-recursive Douglas-Peucker algorithm implementation.\n",
    "        \"\"\"\n",
    "        stroke_len = tf.shape(stroke)[0]\n",
    "        if stroke_len < 3:\n",
    "            return stroke\n",
    "\n",
    "        # Initialize the list of points to keep\n",
    "        simplified_stroke = [stroke[0]]\n",
    "\n",
    "        # Stack for processing: Each entry contains a tuple (start_index, end_index)\n",
    "        stack = [(0, stroke_len - 1)]\n",
    "\n",
    "        while stack:\n",
    "            start_idx, end_idx = stack.pop()\n",
    "\n",
    "            # Get the relevant slice of the stroke\n",
    "            sub_stroke = stroke[start_idx : end_idx + 1]\n",
    "\n",
    "            # Calculate the perpendicular distances of all intermediate points\n",
    "            start, end = sub_stroke[0], sub_stroke[-1]\n",
    "            distances = tf.vectorized_map(\n",
    "                lambda p: point_line_distance(p, start, end), sub_stroke[1:-1]\n",
    "            )\n",
    "\n",
    "            # Find the point with the maximum distance\n",
    "            if tf.size(distances) > 0:\n",
    "                max_distance = tf.reduce_max(distances)\n",
    "                max_idx = tf.argmax(distances) + 1  # +1 because we skip the start point\n",
    "\n",
    "                # If the max distance is greater than epsilon, continue splitting\n",
    "                if max_distance > epsilon:\n",
    "                    stack.append((start_idx, start_idx + max_idx))\n",
    "                    stack.append((start_idx + max_idx, end_idx))\n",
    "                else:\n",
    "                    # Otherwise, keep the start and end points\n",
    "                    simplified_stroke.append(end)\n",
    "            else:\n",
    "                # If no intermediate points exist, just keep the start and end points\n",
    "                simplified_stroke.append(end)\n",
    "\n",
    "        # Return the simplified stroke\n",
    "        return tf.stack(simplified_stroke)\n",
    "\n",
    "    downsampled_strokes = tf.map_fn(elems=normalized_strokes, fn=douglas_peucker)\n",
    "\n",
    "    # Pad to fixed number of strokes and points per stroke\n",
    "    return downsampled_strokes.to_tensor(shape=(64, 64, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeshwinprince/Programming/crohme/datasets/crohme_dataset/data/INKML/val/CROHME2023_val/form_5_f_205_E1022.inkml\n",
      "Displaying app now...\n",
      "tf.Tensor(\n",
      "[[[0.         0.42909095]\n",
      "  [0.09121891 0.46363685]\n",
      "  [0.06434508 0.4181823 ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.21158199 0.80727303]\n",
      "  [0.29598787 0.9999998 ]\n",
      "  [0.2853899  0.03090875]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.36866003 0.8636362 ]\n",
      "  [0.36222556 0.92363656]\n",
      "  [0.35011354 0.94363666]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]], shape=(64, 64, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = next(iter(validation.take(1)))\n",
    "print(normalize_strokes(t[\"strokes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing datasets\n",
    "\n",
    "Now, we can go through our datasets a preprocess all the data. We will need both our vectorizer and our stroke preprocessor together. Since we are going with an encoder-decoder model, we need input data for the decoder as well, which should be the desired output, but just missing the last token, and with the start token added in front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    ground_truth = vectorizer(data[\"ground_truth\"])\n",
    "    decoder_input = tf.concat([[vectorizer(\"[START]\")[0]], ground_truth[:-1]], axis=0)\n",
    "    return (normalize_strokes(data[\"strokes\"]), decoder_input), ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder input: [(+[UNK][UNK]frac{1}{2},[UNK]-[UNK][UNK]frac{1}{2},[UNK]+[UNK][UNK]frac{1}{2},-[UNK][UNK]frac{1}{2},[UNK]-[UNK][UNK]frac{1}{2}\n",
      "True value: (+[UNK][UNK]frac{1}{2},[UNK]-[UNK][UNK]frac{1}{2},[UNK]+[UNK][UNK]frac{1}{2},-[UNK][UNK]frac{1}{2},[UNK]-[UNK][UNK]frac{1}{2})\n",
      "Decoder input: [[UNK][UNK]lim_{t[UNK]rightarrow[UNK]infty}[UNK]|[UNK]gamma(t)|=[UNK]infty\n",
      "True value: [UNK][UNK]lim_{t[UNK]rightarrow[UNK]infty}[UNK]|[UNK]gamma(t)|=[UNK]infty[UNK]\n",
      "Decoder input: [[UNK][UNK]int[UNK]sqrt{g^{(2)}}\n",
      "True value: [UNK][UNK]int[UNK]sqrt{g^{(2)}}[UNK]\n",
      "Decoder input: [xdx=q^2dx\n",
      "True value: xdx=q^2dxx\n",
      "Decoder input: [x[UNK]y[UNK]=[UNK][UNK]sum_{j=1}^n[UNK]x_j[UNK]y_\n",
      "True value: x[UNK]y[UNK]=[UNK][UNK]sum_{j=1}^n[UNK]x_j[UNK]y_j\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(test.shuffle(200_000).take(5)):\n",
    "    pp_data = preprocess_data(data)\n",
    "    # print(pp_data)\n",
    "    print(\"Decoder input:\", token_to_latex(pp_data[0][1]))\n",
    "    print(\"True value:\", token_to_latex(pp_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.map(preprocess_data).shuffle(200_000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "train = train.map(preprocess_data).shuffle(200_000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "validation = (\n",
    "    validation.map(preprocess_data)\n",
    "    .shuffle(200_000)\n",
    "    .batch(32)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this out to make sure it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 1. First element had shape [35] and element 1 had shape [11]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 1. First element had shape [35] and element 1 had shape [11]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "print(next(iter(validation.take(1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "My model is an encoder-decoder architecture, with a CNN for the encoder, a feedforward network to get to the latent space, and a LSTM RNN for the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_strokes = layers.Input(shape=(64, 64, 2))\n",
    "x = layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\")(input_strokes)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(256, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(512, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "latent_space = layers.Dense(1024, activation=\"relu\")(x)\n",
    "latent_space = layers.Dense(512, activation=\"relu\")(latent_space)\n",
    "latent_space = layers.Dense(512, activation=\"relu\")(latent_space)\n",
    "latent_space = layers.Dense(512, activation=\"relu\")(latent_space)\n",
    "latent_space = layers.Dense(512, activation=\"relu\")(latent_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_h = layers.Dense(256, activation=\"relu\")(latent_space)\n",
    "latent_space_c = layers.Dense(256, activation=\"relu\")(latent_space)\n",
    "\n",
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedding = layers.Embedding(input_dim=vocab_size, output_dim=128)(\n",
    "    decoder_input\n",
    ")\n",
    "decoder_lstm = layers.LSTM(128, return_sequences=True)\n",
    "decoder_output = decoder_lstm(\n",
    "    decoder_embedding, initial_state=[latent_space_h, latent_space_c]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layers.Dense(vocab_size, activation=\"softmax\")(decoder_output)\n",
    "model = keras.Model([input_strokes, decoder_input], output)\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now we can finally train our model! We have a ton of training and validation data to use. We'll also save the history so we can get a graph of the change in loss over each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=validation,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"model_checkpoint.h5\", save_best_only=True),\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
