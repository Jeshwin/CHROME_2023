{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROHME 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 18:54:06.716155: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-15 18:54:06.726276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734317646.738081   57338 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734317646.741298   57338 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-15 18:54:06.751836: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `crohme_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734317650.290385   57338 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4968 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import datasets.crohme_dataset  # Register `crohme_dataset`\n",
    "\n",
    "ds = tfds.load(\"crohme_dataset\")  # `crohme_dataset` registered\n",
    "test: tf.data.Dataset = ds[\"test\"]\n",
    "train: tf.data.Dataset = ds[\"train\"]\n",
    "validation: tf.data.Dataset = ds[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Previewing InkML Files\n",
    "\n",
    "I also created a little utility in C++ and GTK to render out an inkml file from the dataset. It reads the InkML file, and renders out the strokes as well as the LaTeX of what it's supposed to be. It was a fun project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 18:54:12.506560: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeshwinprince/Programming/crohme/datasets/crohme_dataset/data/INKML/val/CROHME2016_test/UN_119_em_412.inkml\n",
      "Displaying app now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "random_data_point = next(iter(validation.shuffle(200_000).take(1)))\n",
    "filepath = random_data_point[\"filepath\"].numpy().decode(\"ascii\")\n",
    "os.system(f\"inkmlviewer {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Text Vectorization\n",
    "\n",
    "We will use `pylatexenc` to parse the LaTeX into nodes for custom splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.latexwalker import (\n",
    "    LatexWalker,\n",
    "    LatexMacroNode,\n",
    "    LatexEnvironmentNode,\n",
    "    LatexCharsNode,\n",
    "    LatexGroupNode,\n",
    ")\n",
    "\n",
    "START_TOKEN, END_TOKEN = \"<START>\", \"<END>\"\n",
    "\n",
    "\n",
    "# Define the tokenization function using pylatexenc\n",
    "def latex_tokenizer(latex_string):\n",
    "    \"\"\"\n",
    "    Tokenizes a LaTeX string into tokens using pylatexenc.\n",
    "    \"\"\"\n",
    "    if not latex_string:\n",
    "        return []\n",
    "    walker = LatexWalker(latex_string)\n",
    "\n",
    "    def parse_node(nodelist):\n",
    "        if len(nodelist) == 0:\n",
    "            return []\n",
    "        try:\n",
    "            tokens = []\n",
    "            for node in nodelist:\n",
    "                if not node:\n",
    "                    continue\n",
    "                elif node.isNodeType(LatexMacroNode):\n",
    "                    tokens.append(f\"\\\\{node.macroname}\")\n",
    "                    # Parse arguments if they exist\n",
    "                    tokens += parse_node(node.nodeargd.argnlist)\n",
    "                elif node.isNodeType(LatexEnvironmentNode):\n",
    "                    tokens.append(f\"\\\\begin{{{node.environmentname}}}\")\n",
    "                    tokens += parse_node(node.nodeargd.argnlist)\n",
    "                    tokens += parse_node(node.nodelist)\n",
    "                    tokens.append(f\"\\\\end{{{node.environmentname}}}\")\n",
    "                elif node.isNodeType(LatexCharsNode):\n",
    "                    tokens += list(node.chars)\n",
    "                elif node.isNodeType(LatexGroupNode):\n",
    "                    tokens.append(node.delimiters[0])\n",
    "                    tokens += parse_node(node.nodelist)\n",
    "                    tokens.append(node.delimiters[1])\n",
    "            return tokens\n",
    "        except Exception as e:\n",
    "            return []\n",
    "\n",
    "    nodelist, _, _ = walker.get_latex_nodes()\n",
    "    return parse_node(nodelist)\n",
    "\n",
    "\n",
    "# Wrap the tokenizer for use in TextVectorization\n",
    "def tokenize_fn(latex_tensor):\n",
    "    tokens = []\n",
    "    for latex_string in latex_tensor:\n",
    "        tokenized_string = latex_tokenizer(latex_string.numpy().decode(\"utf-8\"))\n",
    "        tokenized_string.insert(0, START_TOKEN)\n",
    "        tokenized_string.append(END_TOKEN)\n",
    "        tokens.append(tokenized_string)\n",
    "    return tf.ragged.constant(tokens, dtype=tf.string)\n",
    "\n",
    "\n",
    "# Create a TensorFlow-compatible wrapper\n",
    "def tf_tokenizer(latex_string):\n",
    "    return tf.py_function(\n",
    "        func=tokenize_fn,\n",
    "        inp=[latex_string],\n",
    "        Tout=tf.RaggedTensorSpec([None, None], dtype=tf.string),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the vectorizer and use a vocabulary file to adapt it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 18:38:48.691008: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Create the TextVectorization layer\n",
    "max_tokens = 10000  # Adjust depending on your vocabulary size\n",
    "\n",
    "vectorizer = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    standardize=None,  # Custom tokenizer, so no built-in preprocessing\n",
    "    split=tf_tokenizer,\n",
    "    ragged=True,\n",
    ")\n",
    "dataset = tf.data.TextLineDataset(\"vocabulary.txt\")\n",
    "dataset = dataset.map(lambda line: [line])\n",
    "vectorizer.adapt(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it out to make sure it works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[4, 60, 45, 11, 45, 30, 39, 9, 12, 5],\n",
      " [4, 20, 3, 21, 2, 3, 38, 2, 45, 18, 45, 79, 3, 39, 2, 5],\n",
      " [4, 73, 6, 3, 19, 11, 10, 2, 9, 16, 45, 19, 9, 12, 45, 11, 45, 20, 3, 16,\n",
      "  7, 16, 18, 10, 8, 7, 12, 16, 18, 10, 8, 2, 3, 92, 2, 5]                 ,\n",
      " [4, 34, 45, 11, 45, 78, 27, 9, 12, 5],\n",
      " [4, 76, 11, 165, 10, 154, 10, 17, 154, 17, 75, 45, 245, 245, 245, 76, 9, 3,\n",
      "  69, 2, 75, 45, 164, 5]                                                    ]>\n",
      "<START>E = mc^2<END>\n"
     ]
    }
   ],
   "source": [
    "def latex_to_token(string):\n",
    "    return vectorizer(string)\n",
    "\n",
    "\n",
    "id_to_token = {i: token for i, token in enumerate(vectorizer.get_vocabulary())}\n",
    "\n",
    "\n",
    "def token_to_latex(tokens):\n",
    "    return \"\".join([id_to_token[id] for id in tokens.numpy()])\n",
    "\n",
    "\n",
    "latex_array = [\n",
    "    r\"E = mc^2\",\n",
    "    r\"\\frac{a}{b} + \\sqrt{c}\",\n",
    "    r\"\\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6}\",\n",
    "    r\"A = \\pi r^2\",\n",
    "    r\"G=\\begin{bmatrix}1&\\dots&1&0&\\dots&0\\\\ \\ast&\\ast&\\ast&&G^{\\prime}&\\\\ \\end{bmatrix}\",\n",
    "]\n",
    "latex_data = tf.constant(latex_array)\n",
    "\n",
    "# Tokenize and vectorize\n",
    "tokenized_output = latex_to_token(latex_data)\n",
    "print(tokenized_output)\n",
    "\n",
    "E_mc2 = token_to_latex(tokenized_output[0])\n",
    "print(E_mc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the vocabulary just in case. You would still need the custom latex parser function imported to use it in another project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer_vocabulary.txt\", \"r\") as f:\n",
    "    f.write(vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Strokes\n",
    "\n",
    "Instead of images, this model takes in a stream of strokes, such as writing with a stylus on a tablet. Our dataset gives us a list of strokes, and each stroke is itself a list of coordinates [x, y] of the position of the stylus. Both the number of strokes and the length of each strokes changes for every value in our dataset, so we are going to pre-process the stroke data so it will be normalized (scaled to be between 0 and 1), and always fit in a tensor with shape `(64, 64, 2,)`. FOr this, I am using the [Ramer-Douglas-Peucker Algorithm](https://en.wikipedia.org/wiki/Ramer%E2%80%93Douglas%E2%80%93Peucker_algorithm) for polyline decimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_strokes(strokes: tf.RaggedTensor):\n",
    "    # First, scale values to between 0.0 and 1.0\n",
    "    min_vals = tf.reduce_min(strokes, axis=(0, 1))\n",
    "    max_vals = tf.reduce_max(strokes, axis=(0, 1))\n",
    "    normalized_strokes = tf.map_fn(\n",
    "        elems=strokes,\n",
    "        fn=lambda stroke: (stroke - min_vals) / (max_vals - min_vals + 1e-6),\n",
    "    )\n",
    "\n",
    "    def point_line_distance(point, start, end):\n",
    "        \"\"\"\n",
    "        Calculate the perpendicular distance from `point` to the line segment\n",
    "        defined by `start` and `end`.\n",
    "        \"\"\"\n",
    "         # Convert to 3D by adding a zero z-component\n",
    "        point_3d = tf.concat([point, tf.zeros([1], dtype=tf.float32)], axis=0)\n",
    "        start_3d = tf.concat([start, tf.zeros([1], dtype=tf.float32)], axis=0)\n",
    "        end_3d = tf.concat([end, tf.zeros([1], dtype=tf.float32)], axis=0)\n",
    "        \n",
    "        # Compute the cross product between the vectors\n",
    "        cross_prod = tf.linalg.cross(end_3d - start_3d, point_3d - start_3d)\n",
    "        \n",
    "        # Return the perpendicular distance (norm of the cross product / norm of the line segment)\n",
    "        return tf.norm(cross_prod) / tf.norm(end_3d - start_3d)\n",
    "\n",
    "    def douglas_peucker(stroke, epsilon=0.01):\n",
    "        \"\"\"\n",
    "        Non-recursive Douglas-Peucker algorithm implementation.\n",
    "        \"\"\"\n",
    "        stroke_len = tf.shape(stroke)[0]\n",
    "        if stroke_len < 3:\n",
    "            return stroke\n",
    "\n",
    "        # Initialize the list of points to keep\n",
    "        simplified_stroke = [stroke[0]]\n",
    "\n",
    "        # Stack for processing: Each entry contains a tuple (start_index, end_index)\n",
    "        stack = [(0, stroke_len - 1)]\n",
    "\n",
    "        while stack:\n",
    "            start_idx, end_idx = stack.pop()\n",
    "\n",
    "            # Get the relevant slice of the stroke\n",
    "            sub_stroke = stroke[start_idx : end_idx + 1]\n",
    "\n",
    "            # Calculate the perpendicular distances of all intermediate points\n",
    "            start, end = sub_stroke[0], sub_stroke[-1]\n",
    "            distances = tf.vectorized_map(\n",
    "                lambda p: point_line_distance(p, start, end), sub_stroke[1:-1]\n",
    "            )\n",
    "\n",
    "            # Find the point with the maximum distance\n",
    "            if tf.size(distances) > 0:\n",
    "                max_distance = tf.reduce_max(distances)\n",
    "                max_idx = tf.argmax(distances) + 1  # +1 because we skip the start point\n",
    "\n",
    "                # If the max distance is greater than epsilon, continue splitting\n",
    "                if max_distance > epsilon:\n",
    "                    stack.append((start_idx, start_idx + max_idx))\n",
    "                    stack.append((start_idx + max_idx, end_idx))\n",
    "                else:\n",
    "                    # Otherwise, keep the start and end points\n",
    "                    simplified_stroke.append(end)\n",
    "            else:\n",
    "                # If no intermediate points exist, just keep the start and end points\n",
    "                simplified_stroke.append(end)\n",
    "\n",
    "        # Return the simplified stroke\n",
    "        return tf.stack(simplified_stroke)\n",
    "\n",
    "    downsampled_strokes = tf.map_fn(elems=normalized_strokes, fn=douglas_peucker)\n",
    "\n",
    "    # Pad to fixed number of strokes and points per stroke\n",
    "    return downsampled_strokes.to_tensor(shape=(64, 64, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7a5914bf9800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7a5914bf9800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7a5909fbcc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7a5909fbcc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.         0.42909095]\n",
      "  [0.09121891 0.46363685]\n",
      "  [0.06434508 0.4181823 ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.21158199 0.80727303]\n",
      "  [0.29598787 0.9999998 ]\n",
      "  [0.2853899  0.03090875]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.36866003 0.8636362 ]\n",
      "  [0.36222556 0.92363656]\n",
      "  [0.35011354 0.94363666]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]], shape=(64, 64, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = next(iter(validation.take(1)))\n",
    "print(preprocess_strokes(t[\"strokes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing datasets\n",
    "\n",
    "Now, we can go through our datasets a preprocess all the data. We will need both our vectorizer and our stroke preprocessor together. Since we are going with an encoder-decoder model, we need input data for the decoder as well, which should be the desired output, but just missing the last token, and with the start token added in front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    input_strokes = preprocess_strokes(data[\"strokes\"])\n",
    "    ground_truth = vectorizer(data[\"ground_truth\"])\n",
    "    decoder_input = ground_truth[:-1]\n",
    "    decoder_output = ground_truth[1:]\n",
    "    return (input_strokes, decoder_input), decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m200_000\u001b[39m)\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m5\u001b[39m)):\n\u001b[0;32m----> 2\u001b[0m     pp_data \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# print(pp_data)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoder input:\u001b[39m\u001b[38;5;124m\"\u001b[39m, token_to_latex(pp_data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(data):\n\u001b[1;32m      2\u001b[0m     input_strokes \u001b[38;5;241m=\u001b[39m preprocess_strokes(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrokes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m     decoder_input \u001b[38;5;241m=\u001b[39m ground_truth[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m     decoder_output \u001b[38;5;241m=\u001b[39m ground_truth[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(test.shuffle(200_000).take(5)):\n",
    "    pp_data = preprocess_data(data)\n",
    "    # print(pp_data)\n",
    "    print(\"Decoder input:\", token_to_latex(pp_data[0][1]))\n",
    "    print(\"True value:\", token_to_latex(pp_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.map(preprocess_data).shuffle(200_000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "train = train.map(preprocess_data).shuffle(200_000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "validation = (\n",
    "    validation.map(preprocess_data)\n",
    "    .shuffle(200_000)\n",
    "    .batch(32)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this out to make sure it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 1. First element had shape [35] and element 1 had shape [11]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 1. First element had shape [35] and element 1 had shape [11]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "print(next(iter(validation.take(1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "My model is an encoder-decoder architecture, with a CNN for the encoder, a feedforward network to get to the latent space, and a LSTM RNN for the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_strokes = layers.Input(shape=(64, 64, 2))\n",
    "x = layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\")(input_strokes)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(256, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(512, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "latent_space = layers.Dense(1024, activation=\"relu\")(x)\n",
    "latent_space = layers.Dense(512, activation=\"relu\")(latent_space)\n",
    "latent_space = layers.Dense(512, activation=\"relu\")(latent_space)\n",
    "latent_space = layers.Dense(512, activation=\"relu\")(latent_space)\n",
    "latent_space = layers.Dense(512, activation=\"relu\")(latent_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_h = layers.Dense(256, activation=\"relu\")(latent_space)\n",
    "latent_space_c = layers.Dense(256, activation=\"relu\")(latent_space)\n",
    "\n",
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedding = layers.Embedding(input_dim=vectorizer.vocabulary_size(), output_dim=128)(\n",
    "    decoder_input\n",
    ")\n",
    "decoder_lstm = layers.LSTM(128, return_sequences=True)\n",
    "decoder_output = decoder_lstm(\n",
    "    decoder_embedding, initial_state=[latent_space_h, latent_space_c]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layers.Dense(vectorizer.vocabulary_size(), activation=\"softmax\")(decoder_output)\n",
    "model = keras.Model([input_strokes, decoder_input], output)\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now we can finally train our model! We have a ton of training and validation data to use. We'll also save the history so we can get a graph of the change in loss over each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=validation,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"model_checkpoint.h5\", save_best_only=True),\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
