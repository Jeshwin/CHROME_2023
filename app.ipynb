{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROHME 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also import the dataset I created, called `crohme_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.crohme_dataset  # Register `crohme_dataset`\n",
    "\n",
    "ds = tfds.load(\"crohme_dataset\")  # `crohme_dataset` registered\n",
    "test: tf.data.Dataset = ds[\"test\"]\n",
    "train: tf.data.Dataset = ds[\"train\"]\n",
    "validation: tf.data.Dataset = ds[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Previewing InkML Files\n",
    "\n",
    "Alongside this project, I also created a little utility in C++ and GTK to render out an inkml file from the dataset. It reads the InkML file, and renders out the strokes as well as the LaTeX of what it's supposed to be. It was a fun project! Definitely useful for debugging and toy deployments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeshwinprince/Programming/crohme/datasets/crohme_dataset/data/INKML/val/CROHME2023_val/form_5_657_E3283.inkml\n",
      "Displaying app now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "random_data_point = next(iter(validation.shuffle(200_000).take(1)))\n",
    "filepath = random_data_point['filepath'].numpy().decode('ascii')\n",
    "os.system(f\"inkmlviewer {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Text Vectorization\n",
    "\n",
    "In order for our model to use strings as inputs and outputs, we need to convert them into a format that they understand, which is tensors. To do this, we use TextVectorization, which takes a vocabulary of tokens and creates a function that can convert strings into a usable tensor.\n",
    "\n",
    "I have a file called `vocabulary.txt` which contains all the LaTeX tokens I want to look for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 152\n"
     ]
    }
   ],
   "source": [
    "VOCABULARY_FILE = \"vocabulary.txt\"\n",
    "with open(VOCABULARY_FILE, \"r\") as f:\n",
    "    vocab = [lines.strip() for lines in f if lines[0] != '%']\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can then use this list of tokens as the vocabulary for our text vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = layers.TextVectorization(\n",
    "    vocabulary=vocab,\n",
    "    output_mode='int',\n",
    "    standardize=None,\n",
    "    split='character'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to save my vectorizer as a Pickle, a `.pkl` file, so that I can use it for a deployed model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some functions that can convert LaTex strings to tokens, and back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_to_token(string):\n",
    "    return vectorizer(string)\n",
    "\n",
    "id_to_token = {i: token for i, token in enumerate(vectorizer.get_vocabulary())}\n",
    "\n",
    "def token_to_latex(tokens):\n",
    "    return \"\".join([id_to_token[id] for id in tokens.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Strokes\n",
    "\n",
    "This will get more complicated. Instead of images, this model takes in a stream of strokes, such as writing with a stylus on a phone or tablet. Our dataset gives us a list of strokes, and each stroke is itself a list of coordinates [x, y] of the position of the stylus. Both the number of strokes and the length of each strokes changes for every value in our dataset, so we are going to pre-process the stroke data so it will always fit in a tensor with shape `(64, 64, 2,)`. Based on observations of the dataset, there are no more than 45 strokes per input, and no more than 255 points per stroke. So we could simply pad out the variable length to `(64, 256, 2,)`. Then, we can use a sliding window of length 4 to go through all 256 points and basically smooth them out to get to our desired dimension.\n",
    "\n",
    " We also need to normalize our inputs, so that the inputs to our model are always between 0 and 1. This makes the computation much easier. In order to do this, we need to know the minimum and maximum values of the x and y coordinates in each input, and scale each stroke by that amount, since we still need to preserve the relative scale and position of the strokes. So we can just get the min and max and use them to normalize each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_strokes(strokes: tf.RaggedTensor, max_strokes=64, max_points_per_stroke=64, window_size=4):\n",
    "    strokes = strokes.to_tensor(default_value=0.0, shape=(max_strokes, max_points_per_stroke * window_size, 2))\n",
    "    min_vals = tf.reduce_min(strokes, axis=(0, 1))\n",
    "    max_vals = tf.reduce_max(strokes, axis=(0, 1))\n",
    "    normalized_strokes = tf.map_fn(\n",
    "        elems=strokes,\n",
    "        fn=lambda stroke: (stroke - min_vals) / (max_vals - min_vals + 1e-6),\n",
    "    )\n",
    "\n",
    "    # Downsample each stroke using a sliding window\n",
    "    def downsample_with_sliding_window(stroke):\n",
    "        # Pad stroke to ensure divisibility by window_size\n",
    "        padding_needed = window_size - (tf.shape(stroke)[0] % window_size)\n",
    "        padding_needed = tf.cond(\n",
    "            padding_needed == window_size, lambda: 0, lambda: padding_needed\n",
    "        )\n",
    "        padded_stroke = tf.pad(\n",
    "            stroke, [[0, padding_needed], [0, 0]], constant_values=0.0\n",
    "        )\n",
    "\n",
    "        # Reshape into (num_windows, window_size, 2) and compute mean over window_size\n",
    "        reshaped = tf.reshape(padded_stroke, [-1, window_size, 2])\n",
    "        downsampled = tf.reduce_mean(reshaped, axis=1)\n",
    "\n",
    "        # If the resulting downsampled stroke is too long, truncate to max_points_per_stroke\n",
    "        return downsampled[:max_points_per_stroke]\n",
    "\n",
    "    downsampled_strokes = tf.map_fn(\n",
    "        elems=normalized_strokes, fn=downsample_with_sliding_window\n",
    "    )\n",
    "\n",
    "    # Pad to fixed number of strokes and points per stroke\n",
    "    return downsampled_strokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.59055555 0.63455886]\n",
      "  [0.5952778  0.70147055]\n",
      "  [0.6022222  0.7073529 ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.6736111  0.63014704]\n",
      "  [0.69305557 0.6242647 ]\n",
      "  [0.71833336 0.625     ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.68416667 0.7264706 ]\n",
      "  [0.71       0.7220588 ]\n",
      "  [0.73083335 0.7205882 ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]], shape=(64, 64, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = next(iter(validation.shuffle(200_000).take(1)))\n",
    "print(normalize_strokes(t[\"strokes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing datasets\n",
    "\n",
    "Now, we can go through our datasets a preprocess all the data. We will need both our vectorizer and our stroke preprocessor together. Since we are going with an encoder-decoder model, we need input data for the decoder as well, which should be the desired output, but just missing the last token, and with the start token added in front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    ground_truth = vectorizer(data['ground_truth'])\n",
    "    decoder_input = tf.concat([[vectorizer(\"[START]\")[0]], ground_truth[:-1]], axis=0)\n",
    "    return (normalize_strokes(data['strokes']), decoder_input), ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder input: [(+[UNK][UNK]frac{1}{2},[UNK]-[UNK][UNK]frac{1}{2},[UNK]+[UNK][UNK]frac{1}{2},-[UNK][UNK]frac{1}{2},[UNK]-[UNK][UNK]frac{1}{2}\n",
      "True value: (+[UNK][UNK]frac{1}{2},[UNK]-[UNK][UNK]frac{1}{2},[UNK]+[UNK][UNK]frac{1}{2},-[UNK][UNK]frac{1}{2},[UNK]-[UNK][UNK]frac{1}{2})\n",
      "Decoder input: [[UNK][UNK]lim_{t[UNK]rightarrow[UNK]infty}[UNK]|[UNK]gamma(t)|=[UNK]infty\n",
      "True value: [UNK][UNK]lim_{t[UNK]rightarrow[UNK]infty}[UNK]|[UNK]gamma(t)|=[UNK]infty[UNK]\n",
      "Decoder input: [[UNK][UNK]int[UNK]sqrt{g^{(2)}}\n",
      "True value: [UNK][UNK]int[UNK]sqrt{g^{(2)}}[UNK]\n",
      "Decoder input: [xdx=q^2dx\n",
      "True value: xdx=q^2dxx\n",
      "Decoder input: [x[UNK]y[UNK]=[UNK][UNK]sum_{j=1}^n[UNK]x_j[UNK]y_\n",
      "True value: x[UNK]y[UNK]=[UNK][UNK]sum_{j=1}^n[UNK]x_j[UNK]y_j\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(test.shuffle(200_000).take(5)):\n",
    "    pp_data = preprocess_data(data)\n",
    "    # print(pp_data)\n",
    "    print(\"Decoder input:\", token_to_latex(pp_data[0][1]))\n",
    "    print(\"True value:\", token_to_latex(pp_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.map(preprocess_data).shuffle(200_000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "train = train.map(preprocess_data).shuffle(200_000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "validation = validation.map(preprocess_data).shuffle(200_000).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this out to make sure it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 1. First element had shape [35] and element 1 had shape [11]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/crohme/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 1. First element had shape [35] and element 1 had shape [11]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "print(next(iter(validation.take(1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "My model is an encoder-decoder architecture, with a CNN for the encoder, a feedforward network to get to the latent space, and a LSTM RNN for the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_strokes = layers.Input(shape=(64, 64, 2))\n",
    "x = layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\")(input_strokes)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(256, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(512, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "latent_space = layers.Dense(1024, activation='relu')(x)\n",
    "latent_space = layers.Dense(512, activation='relu')(latent_space)\n",
    "latent_space = layers.Dense(512, activation='relu')(latent_space)\n",
    "latent_space = layers.Dense(512, activation='relu')(latent_space)\n",
    "latent_space = layers.Dense(512, activation='relu')(latent_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_h = layers.Dense(256, activation='relu')(latent_space)\n",
    "latent_space_c = layers.Dense(256, activation='relu')(latent_space)\n",
    "\n",
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedding = layers.Embedding(input_dim=vocab_size, output_dim=128)(decoder_input)\n",
    "decoder_lstm = layers.LSTM(128, return_sequences=True)\n",
    "decoder_output = decoder_lstm(decoder_embedding, initial_state=[latent_space_h, latent_space_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layers.Dense(vocab_size, activation='softmax')(decoder_output)\n",
    "model = keras.Model([input_strokes, decoder_input], output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now we can finally train our model! We have a ton of training and validation data to use. We'll also save the history so we can get a graph of the change in loss over each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=validation,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"model_checkpoint.h5\", save_best_only=True),\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
